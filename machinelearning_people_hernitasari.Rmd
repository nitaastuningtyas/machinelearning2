---
title       : "Homework Machinelearning People"  
Description : This is an people analytic machine learning script with HR dataset
Objective   : To create Decision Tree and Random Forest
Data source : https://raw.githubusercontent.com/arikunco/machinelearning/master/dataset/HR_comma_sep.csv
Author      : Hernitasari
---

# Load library
```{r}
library(rpart)
library(randomForest)
library(tree)
library(tidyverse)
library(DataExplorer)
library(readr)
```

# Load dataset 
```{r}
HR_comma_sep <- read.csv('https://raw.githubusercontent.com/arikunco/machinelearning/master/dataset/HR_comma_sep.csv')
```

# Load dataset 
```{r}
df_sdm <- HR_comma_sep
```

# Preview first six rows
```{r}
head(df_sdm)
```

# Preview last six rows 
```{r}
tail(df_sdm)
```

# Column Names 
```{r}
colnames(df_sdm)
```

# Data type per columns 
```{r}
str(df_sdm)
```

# Statistic Description
```{r}
summary(df_sdm)
```

# Check missing value 
```{r}
plot_missing(df_sdm)
```

# Histogram by 'Left'
```{r}
hist(df_sdm$left)
```

# Show 'Left' field become train and data set (sampling 70%)
```{r}
df_sdm$left <- as.factor(df_sdm$left)
train <- sample(1:nrow(df_sdm),as.integer(0.7*nrow(df_sdm)))
traindata <- df_sdm[train,]
testdata <- df_sdm[-train,]
```

# Running Decision Tree
```{r}
tree <- rpart(left ~ ., 
              data = data.frame(traindata), method = "class")
predict(tree, data.frame(testdata),type="class" )
conf_decisionTree <- table(testdata[,'left'],predict(tree, data.frame(testdata),type="class"))
```

# Running Random Forest
```{r}
randomFor <- randomForest(left ~ ., data = data.frame(traindata), ntree=100, importance = TRUE)
predict(randomFor, data.frame(testdata),type="class")
conf_randomFor <- table(testdata[,'left'],predict(randomFor, data.frame(testdata), type="class"))
```

# Meng-Assign TP, FN, FP and TN dari conf table Decision Tree
```{r}
TP_DT <- conf_decisionTree[1, 1] 
FN_DT <- conf_decisionTree[1, 2] 
FP_DT <- conf_decisionTree[2,1] 
TN_DT <- conf_decisionTree[2,2]
```

# Meng-Assign TP, FN, FP and TN dari conf table Random Forest
```{r}
TP_RF <- conf_randomFor[1, 1] 
FN_RF <- conf_randomFor[1, 2] 
FP_RF <- conf_randomFor[2,1] 
TN_RF <- conf_randomFor[2,2] 
```

# Menghitung akurasi Decision Tree
```{r}
acc_DT <- (TP_DT+TN_DT)/(TP_DT+FN_DT+FP_DT+TN_DT)
acc_DT
```

# Menghitung akurasi Random Forest
```{r}
acc_RF <- (TP_RF+TN_RF)/(TP_RF+FN_RF+FP_RF+TN_RF)
acc_RF
```

# Menghitung presisi Decision Tree
```{r}
prec_DT <- TP_DT / (TP_DT+FP_DT)
prec_DT
```

# Menghitung presisi Random Forest
```{r}
prec_RF <- TP_RF / (TP_RF+FP_RF)
prec_RF
```

# Menghitung recall Decision Tree
```{r}
rec_DT <- TP_DT / (TP_DT+FN_DT)
rec_DT
```

# Menghitung recall Random Forest
```{r}
rec_RF <- TP_RF / (TP_RF+FN_RF)
rec_RF
```

# Kesimpulan : Berdasarkan dari data akurasi, presisi dan recall, metode random forest lebih baik digunakan dibandingkan decision tree karena memiliki nilai yang lebih tinggi

        